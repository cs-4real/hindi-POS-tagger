{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a77153dc-a811-4f66-9f9a-c0d4dd41a4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package indian to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package indian is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences in the tagged file are 540\n",
      "Training dataset length:  486\n",
      "Testing dataset length:  53\n",
      "Accuracy:  0.8111964873765093\n",
      "[('भारत', 'NNP'), ('वह', 'PRP'), ('महान', 'JJ'), ('देश', 'NN'), ('है', 'VFM'), ('जहां', 'NLOC'), ('अनेक', 'QF'), ('प्रकार', 'NN'), ('के', 'PREP'), ('योद्धा', 'Unk'), (',', 'PUNC'), ('देश', 'NN'), ('प्रेमी', 'Unk'), ('जन्म', 'Unk'), ('लिए', 'PREP'), ('और', 'CC'), ('अपनी', 'PRP'), ('आखिरी', 'Unk'), ('सांस', 'Unk'), ('तक', 'PREP'), ('देश', 'NN'), ('के', 'PREP'), ('लिए', 'PREP'), ('लड़ते', 'Unk'), ('रहे।', 'Unk')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import indian\n",
    "from nltk.tag import tnt\n",
    "import string\n",
    "\n",
    "# Downloading Indian Languages Corpora which consists Hindi, Bangla, Marathi and Telugu corpus respectively\n",
    "nltk.download(\"indian\")\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# Training the POS Tagger Model using Hindi dataset\n",
    "def train():\n",
    "    taggedSet = \"hindi.pos\"\n",
    "    wordSet = indian.sents(taggedSet)\n",
    "    count = 0\n",
    "    \n",
    "    # Joining dataset words to form a sentence\n",
    "    for sen in wordSet:\n",
    "        count += 1\n",
    "        sen = \" \".join([\n",
    "            \" \" + i if not i.startswith(\"\\\"\") and i not in string.punctuation else i\n",
    "            for i in sen\n",
    "        ]).strip()\n",
    "    \n",
    "    # Total Sentence Count\n",
    "    print(\"Total sentences in the tagged file are\", count)\n",
    "    \n",
    "    # Splitting dataset into Training Data and Test Data\n",
    "    trainPerc = 0.9\n",
    "    trainRows = int(trainPerc * count)\n",
    "    testRows = trainRows + 1\n",
    "    \n",
    "    # Slicing the corpus\n",
    "    data = indian.tagged_sents(taggedSet)\n",
    "    train_data = data[:trainRows]\n",
    "    test_data = data[testRows:]\n",
    "    \n",
    "    # Stats\n",
    "    print(\"Training dataset length: \", len(train_data))\n",
    "    print(\"Testing dataset length: \", len(test_data))\n",
    "    \n",
    "    pos_tagger = tnt.TnT()\n",
    "    pos_tagger.train(train_data)\n",
    "    print(\"Accuracy: \", pos_tagger.accuracy(test_data))\n",
    "    \n",
    "    return pos_tagger\n",
    "\n",
    "# Tagging function to tag all words in a sentence\n",
    "def tagger(pos_tagger, sentenceToBeTagged):\n",
    "    tokenized = nltk.word_tokenize(sentenceToBeTagged)\n",
    "    return pos_tagger.tag(tokenized)\n",
    "\n",
    "# Main Driving Module\n",
    "if __name__ == \"__main__\":\n",
    "    pos_tagger = train()\n",
    "    sentence_to_be_tagged = \"भारत वह महान देश है जहां अनेक प्रकार के योद्धा, देश प्रेमी जन्म लिए और अपनी आखिरी सांस तक देश के लिए लड़ते रहे।\"\n",
    "    print(tagger(pos_tagger, sentence_to_be_tagged))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
